# -*- coding: utf-8 -*-
"""LDA1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u6BSHTlqD9HqCLGH_L_RUEoivYMYYfI6
"""

# Step 1: Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.decomposition import PCA
import seaborn as sns

# Step 2: Load the Iris dataset
data = datasets.load_iris()
features = data.data
labels = data.target
class_names = data.target_names

print("Sample feature data:\n", features[:5])
print("Sample target labels:\n", labels[:5])
print("Classes:", class_names)

# Step 3: Standardize the feature data
scaler = StandardScaler()
standardized_features = scaler.fit_transform(features)
print("Standardized Features (first 5 rows):\n", standardized_features[:5])

# Step 4: Apply LDA for dimensionality reduction
lda_model = LDA(n_components=2)
transformed_data = lda_model.fit_transform(standardized_features, labels)
print("LDA Transformed Data (first 5 rows):\n", transformed_data[:5])

# Step 5: Visualize the LDA-transformed data in 2D
plt.figure(figsize=(10, 5))
colors = ['red', 'green', 'blue']

for idx, col, class_label in zip(range(len(class_names)), colors, class_names):
    plt.scatter(transformed_data[labels == idx, 0], transformed_data[labels == idx, 1],
                alpha=0.8, c=col, label=class_label)

plt.xlabel("LDA Component 1")
plt.ylabel("LDA Component 2")
plt.title("LDA Projection of Iris Dataset")
plt.legend()
plt.show()

# Step 6: Apply PCA for comparison
pca_model = PCA(n_components=2)
pca_transformed = pca_model.fit_transform(standardized_features)
print("PCA Transformed Data (first 5 rows):\n", pca_transformed[:5])

# Step 7: Standardize the data
scaler = StandardScaler()
standardized_data = scaler.fit_transform(features)

# Apply LDA
lda_model = LDA(n_components=2)
lda_transformed = lda_model.fit_transform(standardized_data, labels)

# Apply PCA
pca_model = PCA(n_components=2)
pca_transformed = pca_model.fit_transform(standardized_data)

# Plot the LDA and PCA results side-by-side for comparison
fig, (ax_lda, ax_pca) = plt.subplots(1, 2, figsize=(15, 6))

# LDA plot
colors = ['red', 'green', 'blue']
for idx, col, class_label in zip(range(len(class_names)), colors, class_names):
    ax_lda.scatter(lda_transformed[labels == idx, 0], lda_transformed[labels == idx, 1],
                   alpha=0.8, color=col, label=class_label)
ax_lda.set_xlabel("LDA Component 1")
ax_lda.set_ylabel("LDA Component 2")
ax_lda.set_title("LDA: Iris Data Projection")
ax_lda.legend()

# PCA plot
for idx, col, class_label in zip(range(len(class_names)), colors, class_names):
    ax_pca.scatter(pca_transformed[labels == idx, 0], pca_transformed[labels == idx, 1],
                   alpha=0.8, color=col, label=class_label)
ax_pca.set_xlabel("PCA Component 1")
ax_pca.set_ylabel("PCA Component 2")
ax_pca.set_title("PCA: Iris Data Projection")
ax_pca.legend()

plt.suptitle("Comparison of LDA and PCA on the Iris Dataset")
plt.show()